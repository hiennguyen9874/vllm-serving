{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Qwen3-VL-30B-A3B-Thinking'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "model_name = client.models.list().data[0].id\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: ChatCompletion(id='chatcmpl-699fa5c9b8a74619bd735eb23ccde14a', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"\\n\\nHere's a concise introduction to Large Language Models (LLMs):\\n\\n**Large Language Models (LLMs)** are advanced AI systems trained on vast amounts of text data (like books, websites, and articles) to understand and generate human-like language. They use deep learning (specifically transformer architectures) with **billions of parameters** (adjustable settings) to recognize patterns, context, and meaning.\\n\\n**Key characteristics:**\\n- **Scale:** Trained on massive datasets (often terabytes of text).\\n- **Versatility:** Can write stories, code, emails, scripts, perform translations, answer questions, and more.\\n- **Predictive Power:** Generate text token-by-token, predicting the next word based on context.\\n- **Examples:** GPT-4 (OpenAI), Gemini (Google), Llama 3 (Meta), Claude (Anthropic).\\n\\n**Why they matter:**  \\nLLMs enable natural, human-like interaction with AI, driving innovations in chatbots, content creation, coding assistance, and research. However, they can **hallucinate** (make up facts), reflect biases in training data, and lack true understanding. They are powerful tools—not sentient beings—relying entirely on patterns in their training data.\\n\\n**In short:** LLMs are the cutting edge of AI language understanding, transforming how we interact with technology, but they require careful use due to inherent limitations.\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content='Okay, the user asked for a short introduction to large language models. Let me start by recalling the basics. LLMs are a type of AI that processes and generates human-like text. They\\'re trained on massive amounts of data. But I need to keep it concise since the user specified \"short.\"\\n\\nHmm, the user might be new to the topic. Maybe they\\'re a student, a professional looking to understand the basics, or someone curious about AI trends. Their main need is a quick overview without too much jargon. They probably want to know what LLMs are, how they work, and why they matter.\\n\\nWait, should I mention specific examples? Like GPT-3 or BERT? Yes, including a few well-known models can make it relatable. But since it\\'s a short intro, just naming them without details might suffice. Also, the user might not know the technical terms, so explaining \"parameters\" in simple terms is important. \\n\\nI should cover key points: what LLMs are, how they\\'re built (training on data), their capabilities (text generation, translation), and why they\\'re significant. Avoid diving into technicalities like transformer architecture unless necessary. \\n\\nOh, and potential pitfalls? Maybe mention that they can make mistakes or have biases, but since it\\'s an introduction, maybe just a brief note on limitations. However, the user said \"short,\" so maybe skip the drawbacks unless it\\'s crucial. But a small note about being tools with limitations could be helpful.\\n\\nCheck if the user might need this for a presentation or a quick reference. They might want to know applications too. Applications like chatbots, content creation, coding assistance. But keep it brief. \\n\\nAlso, avoid acronyms without explanation. Spell out \"LLM\" first. Make sure the structure is logical: definition, how they work, examples, applications, and a note on limitations. \\n\\nWait, the user didn\\'t ask for examples, but including a couple of model names adds context. But don\\'t list too many. GPT, Gemini, Llama are the most recognized. \\n\\nFinally, end with why it matters—impact on various fields. Keep the tone informative but accessible. No markdown, just plain text. Alright, time to draft a concise summary.\\n'), stop_reason=None, token_ids=None)], created=1760147067, model='Qwen3-VL-30B-A3B-Thinking', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=747, prompt_tokens=20, total_tokens=767, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None, prompt_token_ids=None, kv_transfer_params=None)\n"
     ]
    }
   ],
   "source": [
    "chat_response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Give me a short introduction to large language models.\"},\n",
    "    ],\n",
    "    # temperature=0.7,\n",
    "    # top_p=0.8,\n",
    "    # top_k=20,\n",
    "    # max_tokens=8192,\n",
    "    # presence_penalty=1.5,\n",
    "    # extra_body={\"chat_template_kwargs\": {\"enable_thinking\": True}},\n",
    ")\n",
    "print(\"Chat response:\", chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nHere's a concise introduction to Large Language Models (LLMs):\\n\\n**Large Language Models (LLMs)** are advanced AI systems trained on vast amounts of text data (like books, websites, and articles) to understand and generate human-like language. They use deep learning (specifically transformer architectures) with **billions of parameters** (adjustable settings) to recognize patterns, context, and meaning.\\n\\n**Key characteristics:**\\n- **Scale:** Trained on massive datasets (often terabytes of text).\\n- **Versatility:** Can write stories, code, emails, scripts, perform translations, answer questions, and more.\\n- **Predictive Power:** Generate text token-by-token, predicting the next word based on context.\\n- **Examples:** GPT-4 (OpenAI), Gemini (Google), Llama 3 (Meta), Claude (Anthropic).\\n\\n**Why they matter:**  \\nLLMs enable natural, human-like interaction with AI, driving innovations in chatbots, content creation, coding assistance, and research. However, they can **hallucinate** (make up facts), reflect biases in training data, and lack true understanding. They are powerful tools—not sentient beings—relying entirely on patterns in their training data.\\n\\n**In short:** LLMs are the cutting edge of AI language understanding, transforming how we interact with technology, but they require careful use due to inherent limitations.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, the user asked for a short introduction to large language models. Let me start by recalling the basics. LLMs are a type of AI that processes and generates human-like text. They\\'re trained on massive amounts of data. But I need to keep it concise since the user specified \"short.\"\\n\\nHmm, the user might be new to the topic. Maybe they\\'re a student, a professional looking to understand the basics, or someone curious about AI trends. Their main need is a quick overview without too much jargon. They probably want to know what LLMs are, how they work, and why they matter.\\n\\nWait, should I mention specific examples? Like GPT-3 or BERT? Yes, including a few well-known models can make it relatable. But since it\\'s a short intro, just naming them without details might suffice. Also, the user might not know the technical terms, so explaining \"parameters\" in simple terms is important. \\n\\nI should cover key points: what LLMs are, how they\\'re built (training on data), their capabilities (text generation, translation), and why they\\'re significant. Avoid diving into technicalities like transformer architecture unless necessary. \\n\\nOh, and potential pitfalls? Maybe mention that they can make mistakes or have biases, but since it\\'s an introduction, maybe just a brief note on limitations. However, the user said \"short,\" so maybe skip the drawbacks unless it\\'s crucial. But a small note about being tools with limitations could be helpful.\\n\\nCheck if the user might need this for a presentation or a quick reference. They might want to know applications too. Applications like chatbots, content creation, coding assistance. But keep it brief. \\n\\nAlso, avoid acronyms without explanation. Spell out \"LLM\" first. Make sure the structure is logical: definition, how they work, examples, applications, and a note on limitations. \\n\\nWait, the user didn\\'t ask for examples, but including a couple of model names adds context. But don\\'t list too many. GPT, Gemini, Llama are the most recognized. \\n\\nFinally, end with why it matters—impact on various fields. Keep the tone informative but accessible. No markdown, just plain text. Alright, time to draft a concise summary.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.choices[0].message.reasoning_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
